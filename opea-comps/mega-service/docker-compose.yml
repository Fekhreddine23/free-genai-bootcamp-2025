version: '3.8'

services:
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"
      - "4317:4317"
      - "4318:4318"
      - "9411:9411"
      - "9000:11434"
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"
      COLLECTOR_OTLP_ENABLED: "true"
     

  mega-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mega-service
    ports:
      - "8000:8000"
    environment:
      LLM_SERVICE_HOST_IP: "ollama-service"
      LLM_SERVICE_PORT: "11434"
      LLM_SERVICE_ENDPOINT: "/api/chat"
    depends_on:
      - ollama-service
      - jaeger

  ollama-service:
    image: ollama/ollama
    container_name: ollama-service
    ports:
      - "${LLM_ENDPOINT_PORT}:11434"
     
    environment:
      no_proxy: ${no_proxy:-localhost}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      LLM_MODEL_ID: ${LLM_MODEL_ID:-default-model}
      LLM_MODEL_VERSION: ${LLM_MODEL_VERSION:-latest}
      host_ip: ${host_ip:-127.0.0.1}

volumes:
  ollama-data: